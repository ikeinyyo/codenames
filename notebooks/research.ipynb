{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "humanitarian-closing",
   "metadata": {},
   "source": [
    "# Research\n",
    "\n",
    "This notebook is for research about different word embedding libraries. The goal is know about the features of this library to select the best way to aboard our project.\n",
    "\n",
    "We are going to investigate about these libraries:\n",
    "- fasttext\n",
    "- gemsim\n",
    "- nltk\n",
    "- SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peripheral-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import fasttext\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rocky-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = {\n",
    "    'red': ['key', 'green', 'force', 'casino', 'hospital', 'robot', 'spell', 'red'],\n",
    "    'blue': ['eagle', 'fair', 'lap', 'beach', 'back', 'sound', 'bottle', 'hole', 'alien'],\n",
    "    'neutral': ['dog', 'mole', 'wind', 'apple', 'whale', 'berry', 'pool'],\n",
    "    'murderer': ['staff']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-fighter",
   "metadata": {},
   "source": [
    "## Fist step\n",
    "\n",
    "The first step is get a clue witch identify a word. And try to get the same clue for two words. We will test with 'red' and 'green', the obviously is to say 'color' as a clue. We will make it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-suite",
   "metadata": {},
   "source": [
    "### fasttext\n",
    "\n",
    "First, we are going to test `fasttext`. We are going to use a pretrained word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-minute",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import fasttext.util\n",
    "FAST_TEXT_MODEL = \"cc.en.300.bin\" # Model name in fasttext\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "superior-basketball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8113083243370056, 'blue'),\n",
       " (0.8055115342140198, 'yellow'),\n",
       " (0.7738474011421204, 'purple'),\n",
       " (0.7048869132995605, 'orange'),\n",
       " (0.6970385909080505, 'pink'),\n",
       " (0.6968856453895569, 'non-red'),\n",
       " (0.682639479637146, 'crimson'),\n",
       " (0.6794082522392273, 'green'),\n",
       " (0.6712507605552673, 'white'),\n",
       " (0.6558310389518738, 'light-red')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "amino-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7388068437576294, 'greeen'),\n",
       " (0.7049704194068909, 'blue'),\n",
       " (0.6820159554481506, 'yellow'),\n",
       " (0.6794081926345825, 'red'),\n",
       " (0.6742905378341675, 'green-'),\n",
       " (0.6663212180137634, 'purple'),\n",
       " (0.6522365212440491, 'green-ish'),\n",
       " (0.6520159840583801, 'green.The'),\n",
       " (0.6385214328765869, '-green'),\n",
       " (0.6341298818588257, 'orange')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-archive",
   "metadata": {},
   "source": [
    "As you can see, it is not a very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-czech",
   "metadata": {},
   "source": [
    "### Using gensim with FastText\n",
    "\n",
    "We can use FastText model with gensim to get the most similar words.\n",
    "\n",
    "More info [here](https://radimrehurek.com/gensim/models/fasttext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "written-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model = FastText.load_fasttext_format(FAST_TEXT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "private-logic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue', 0.8273435831069946),\n",
       " ('yellow', 0.8116556406021118),\n",
       " ('purple', 0.7858149409294128),\n",
       " ('orange', 0.7306221723556519),\n",
       " ('greeen', 0.698380172252655),\n",
       " ('pink', 0.6954872608184814),\n",
       " ('green-colored', 0.6573896408081055),\n",
       " ('white', 0.6534684300422668),\n",
       " ('blue-green', 0.6492818593978882),\n",
       " ('green-ish', 0.6438031196594238)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['red', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-hygiene",
   "metadata": {},
   "source": [
    "### Get Synonyms and Antonyms\n",
    "\n",
    "To improve the model, is a good idea use also the synonyms and antonyms. We have created this two methods to help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "removable-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gallardo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /Users/gallardo/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "round-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_synonyms(word, lang='eng', output_lang='eng'):\n",
    "    synonyms = [syns.lemma_names(lang=output_lang) for syns in wn.synsets(word, lang=lang)]\n",
    "    flat = list([item.lower() for sublist in synonyms for item in sublist])\n",
    "    return sorted(set(flat),key=flat.count)[::-1]\n",
    "\n",
    "def get_antonyms(word, lang='eng'):\n",
    "    help_lang = 'eng'\n",
    "    translated_word = get_synonyms(word, lang=lang, output_lang=help_lang)\n",
    "    antonyms = []\n",
    "    for syns in wn.synsets(translated_word[0], lang=help_lang):\n",
    "        for lemma in syns.lemmas(lang=help_lang):\n",
    "            for antonym in lemma.antonyms():\n",
    "                antonyms_lemma = [syns.lemma_names(lang=lang) for syns in wn.synsets(antonym.name(), lang=help_lang)]\n",
    "                antonyms.append([item for sublist in antonyms_lemma for item in sublist])\n",
    "    flat = list([item for sublist in antonyms for item in sublist])\n",
    "    return sorted(set(flat),key=flat.count)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "judicial-channel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: ['red', 'crimson', 'red_river', 'ruby-red', 'violent', 'red_ink', 'cherry-red', 'ruddy', 'ruby', 'reddened', 'bolshy', 'cherry', 'blood-red', 'cerise', 'bolshevik', 'scarlet', 'redness', 'reddish', 'flushed', 'carmine', 'loss', 'bolshie', 'red-faced', 'marxist']\n",
      "Antonyms: ['gain', 'profit', 'win', 'advance', 'make', 'gain_ground', 'hit', 'addition', 'gather', 'earn', 'pull_ahead', 'make_headway', 'acquire', 'realize', 'reach', 'get_ahead', 'bring_in', 'put_on', 'increase', 'attain', 'amplification', 'take_in', 'realise', 'benefit', 'clear', 'derive', 'pull_in', 'arrive_at']\n"
     ]
    }
   ],
   "source": [
    "print('Synonyms:', get_synonyms('red'))\n",
    "print('Antonyms:', get_antonyms('red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "racial-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: ['green', 'commons', 'jet', 'immature', 'putting_green', 'putting_surface', 'k', 'super_acid', 'honey_oil', 'greens', 'dark-green', 'greenness', 'fleeceable', 'special_k', 'william_green', 'park', 'cat_valium', 'gullible', 'viridity', 'light-green', 'super_c', 'green_river', 'unripened', 'common', 'leafy_vegetable', 'unripe', 'greenish']\n",
      "Antonyms: ['ripe', 'good', 'right', 'advanced', 'mature']\n"
     ]
    }
   ],
   "source": [
    "print('Synonyms:', get_synonyms('green'))\n",
    "print('Antonyms:', get_antonyms('green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-worcester",
   "metadata": {},
   "source": [
    "In the case of 'red' and 'pink', 'color' is not a synonyms, therefore it's not very useful. But we could be use for other cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-accent",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "We can calculate the words similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "endless-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(word1, word2):\n",
    "    words1 = get_synonyms(word1)\n",
    "    words2 = get_synonyms(word2)\n",
    "    max_similarity = 0\n",
    "    pair = None\n",
    "    for w1 in words1:\n",
    "        for w2 in words2:\n",
    "            max_similarity = max(max_similarity, model.wv.similarity(w1, w2))\n",
    "    return max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "modified-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8483072"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_similarity('red', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-glasgow",
   "metadata": {},
   "source": [
    "### Combination of words\n",
    "\n",
    "For play Codenames, is a good idea to try to find a combination of similar words, and then look for a clue. We can find the best combination for the words in the board. \n",
    "\n",
    "**Note:** for next steps we have to ensure that the combination is not in conflict with other words in the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "internal-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_similar_combinations(candidate_words, k):\n",
    "    all_pairs = combinations(candidate_words, k)\n",
    "    scored_pairs = [(calculate_similarity(p[0], p[1]), p)\n",
    "                    for p in all_pairs]\n",
    "    return sorted(scored_pairs, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baking-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483072, ('green', 'red'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_combinations(board['red'], 2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-horse",
   "metadata": {},
   "source": [
    "### spaCy\n",
    "\n",
    "Also, we can use spaCy to get similarity of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "overhead-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "married-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7822252390048066"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('red').similarity(nlp('green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "japanese-edward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maroon',\n",
       " 'white',\n",
       " 'burgundy',\n",
       " 'purple',\n",
       " 'lime',\n",
       " 'beige',\n",
       " 'dark',\n",
       " 'reddish',\n",
       " 'coloured',\n",
       " 'pale']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spacy_most_similar(word, topn=100):\n",
    "    ms = nlp_ru.vocab.vectors.most_similar(\n",
    "      nlp_ru(word).vector.reshape(1,nlp_ru(word).vector.shape[0]), n=topn)\n",
    "    return list(set([nlp_ru.vocab.strings[w].lower() for w in ms[0][0]]))[:10]\n",
    "\n",
    "spacy_most_similar('red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-print",
   "metadata": {},
   "source": [
    "### Similarity or synonyms are not relevan\n",
    "\n",
    "For other words we can use synonyms, but for 'red' and 'green' we need to work with the meaning of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "frozen-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definition(word):\n",
    "    return wn.synsets(word)[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "chinese-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red color or pigment; the chromatic color resembling the hue of blood\n",
      "green color or pigment; resembling the color of growing grass\n"
     ]
    }
   ],
   "source": [
    "print(get_definition('red'))\n",
    "print(get_definition(\"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-oxford",
   "metadata": {},
   "source": [
    "For the first time, we found the word 'color'. We can try to find the key words in the words meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "satellite-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definition_similarity(word1, word2):\n",
    "    return nlp(get_definition(word1)).similarity(nlp(get_definition(word2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "controlled-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9311594117249767"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_definition_similarity('red', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "wooden-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_words_from_definition(word):\n",
    "    definition = nlp(get_definition(word))\n",
    "    words = [token.text for token in definition if not token.is_stop and not token.is_punct]\n",
    "    counter =  Counter(words)\n",
    "    return sorted(counter, key=counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "considerable-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color', 'red', 'pigment', 'chromatic', 'resembling', 'hue', 'blood']\n",
      "['color', 'green', 'pigment', 'resembling', 'growing', 'grass']\n"
     ]
    }
   ],
   "source": [
    "print(get_words_from_definition('red'))\n",
    "print(get_words_from_definition('green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "enabling-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_words_from_definition(words):\n",
    "    word_definition = list(map(lambda word: get_words_from_definition(word), words))\n",
    "    return list(set(word_definition[0]).intersection(*word_definition[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-communication",
   "metadata": {},
   "source": [
    "Using the definitions we can found a words witch appears in both definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "figured-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pigment', 'resembling', 'color']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_words_from_definition([\"red\", \"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "continuous-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations_with_same_words_in_definition(candidate_words, k):\n",
    "    all_pairs = combinations(candidate_words, k)\n",
    "    match_pairs = [(match_words_from_definition(p), p)\n",
    "                    for p in all_pairs]\n",
    "    return list(filter(lambda pair: len(pair[0]), match_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "beneficial-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['mechanism'], ('key', 'robot')),\n",
       " (['pigment', 'resembling', 'color'], ('green', 'red'))]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_combinations_with_same_words_in_definition(board['red'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "defined-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['person'], ('lap', 'alien')), (['neck'], ('back', 'bottle'))]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_combinations_with_same_words_in_definition(board['blue'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "potential-philippines",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['person'], ('lap', 'alien')),\n",
       " (['neck'], ('back', 'bottle')),\n",
       " (['effect'], ('sound', 'force')),\n",
       " (['mechanism'], ('key', 'robot')),\n",
       " (['pigment', 'resembling', 'color'], ('green', 'red'))]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_combinations_with_same_words_in_definition([*board['blue'], *board['red']], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "suitable-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the posterior part of a human (or animal) body from the neck to the end of the spine\n",
      "a glass or plastic vessel used for storing drinks or other liquids; typically cylindrical without handles and with a narrow neck that can be plugged or capped\n"
     ]
    }
   ],
   "source": [
    "print(get_definition('back'))\n",
    "print(get_definition('bottle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "portable-bacteria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166554279210518"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_definition_similarity('key', 'robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-gravity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (condenames)",
   "language": "python",
   "name": "condenames"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
